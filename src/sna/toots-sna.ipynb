{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6d55da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import networkx\n",
    "import pandas as pd\n",
    "import glob\n",
    "import nltk\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModelForSequenceClassification, TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "import os\n",
    "import os, json, openai, warnings, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image, display\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81dfcf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "instance_stats = {\n",
    "  \"domain\": \"mastodon.social\",\n",
    "  \"title\": \"Mastodon\",\n",
    "  \"version\": \"4.1.2+nightly-20230627\",\n",
    "  \"source_url\": \"https://github.com/mastodon/mastodon\",\n",
    "  \"description\": \"The original server operated by the Mastodon gGmbH non-profit\",\n",
    "  \"usage\": {\n",
    "    \"users\": {\n",
    "      \"active_month\": 221664\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751e3221",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_path = \"../../data/replied_toots_2023_05_27/\"\n",
    "datasets = glob.glob(\"{}/toots_mastodon*.parquet\".format(base_path))\n",
    "toots_df = pd.concat([pd.read_parquet(data) for data in datasets], axis=0).reset_index(drop=True)\n",
    "print(len(toots_df))\n",
    "toots_df = toots_df.drop_duplicates(subset=['id'])\n",
    "toots_df.describe()\n",
    "# df = df[(df['content'].apply(len) < 256) & (df['language'] == 'en')]\n",
    "# df = df[~df['content'].isna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ac030e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets = glob.glob(\"{}/status_mastodon*.parquet\".format(base_path))\n",
    "statuses_df = pd.concat([pd.read_parquet(data) for data in datasets], axis=0).reset_index(drop=True)\n",
    "statuses_df = statuses_df.drop_duplicates(subset=['id'])\n",
    "statuses_df.loc[statuses_df['parent_reply_id'].isin(statuses_df['parent_reply_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4762999b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import pyarrow\n",
    "# users_path = '../../data/2023-06-27-10kusers-dump.parquet'\n",
    "# batch_size = 1000\n",
    "# user_parquet = pyarrow.parquet.ParquetFile(users_path)\n",
    "# pq_iter = user_parquet.iter_batches(batch_size=batch_size)\n",
    "# r = []\n",
    "# user_df_batches = []\n",
    "# for iter_ in pq_iter:\n",
    "#     batch_df = iter_.to_pandas()\n",
    "#     user_df_batches.append(batch_df)\n",
    "# user_df = pd.concat(user_df_batches, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f102adc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accts = toots_df['account'].apply(lambda acc: acc['acct'])\n",
    "display(toots_df['replies_count'].value_counts(), toots_df['reblogs_count'].value_counts(), toots_df['favourites_count'].value_counts())\n",
    "\n",
    "replies_only_df = toots_df.loc[toots_df['replies_count'] > 2]\n",
    "# out of 167K, only 20K have replies, and 99% are less then 1.\n",
    "# sns.histplot(data=replies_only_df, y=\"replies_count\")\n",
    "sns.histplot(data=replies_only_df, x=\"replies_count\", binwidth=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b43df2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Stats to dump \n",
    "# Number of nodes\n",
    "# Average REALY connection per person (Degree)\n",
    "# Average closeness\n",
    "# Clustering coeffiecietnt\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import networkx as nx\n",
    "\n",
    "# First we have to add edges using the replies - and each reply may not exist?\n",
    "\n",
    "# toots_df.loc[toots_df['in_reply_to_id'] & toots_df['in_reply_to_account_id']\n",
    "# toots_reply = toots_df.loc[~toots_df['in_reply_to_account_id'].isnull()].copy()\n",
    "# toots_reply['account_id_source'] = toots_reply['account'].apply(lambda acc: acc['id'])\n",
    "# toots_reply = toots_reply.loc[toots_reply['in_reply_to_account_id'] == toots_reply['account_id_source']]\n",
    "\n",
    "# toots_reply = toots_df.loc[toots_df['replies_count'] > 0]\n",
    "\n",
    "\n",
    "# a=nx.Graph()\n",
    "\n",
    "# len(toots_reply)\n",
    "# for index, tr in toots_reply.iterrows():\n",
    "#     a.add_edge(tr['in_reply_to_account_id'], tr['account']['id'])\n",
    "#     break\n",
    "\n",
    "# nx.draw(a, with_labels=True, font_weight='light')\n",
    "# toots_reply['in_reply_to_account_id'] != toots_reply['account_id_source']]\n",
    "# pd.set_option('max_colwidth', 800)\n",
    "# toots_reply.iloc[5].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88724c2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import networkx as nx\n",
    "\n",
    "statuses_df['in_reply_to_account_id'].value_counts()\n",
    "\n",
    "# Lets collate things by the influencer nodes \n",
    "influencers = defaultdict(set)\n",
    "for k, status in statuses_df.iterrows():\n",
    "    if status['parent_account_id'] == None: # just a very few this is not filled incorrectly i believe\n",
    "        continue\n",
    "    influencers[status['parent_account_id']].add(status['account']['id'])\n",
    "    \n",
    "# from pprint import pprint\n",
    "# pprint(influencers)\n",
    "    \n",
    "G=nx.Graph()\n",
    "\n",
    "for dest, edges in influencers.items():\n",
    "    for src in edges:\n",
    "        G.add_edge(src, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcdbce0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deg=nx.degree(G)\n",
    "\n",
    "degree_sequence = sorted((d for n, d in G.degree()), reverse=True)\n",
    "dmax = max(degree_sequence)\n",
    "\n",
    "fig = plt.figure(\"Degree of a random graph\", figsize=(8, 8))\n",
    "# Create a gridspec for adding subplots of different sizes\n",
    "axgrid = fig.add_gridspec(5, 4)\n",
    "\n",
    "# Too slow\n",
    "# ax0 = fig.add_subplot(axgrid[0:3, :])\n",
    "# Gcc = G.subgraph(sorted(nx.connected_components(G), key=len, reverse=True)[0])\n",
    "# pos = nx.spring_layout(Gcc, seed=10396953)\n",
    "# nx.draw_networkx_nodes(Gcc, pos, ax=ax0, node_size=20)\n",
    "# nx.draw_networkx_edges(Gcc, pos, ax=ax0, alpha=0.4)\n",
    "# ax0.set_title(\"Connected components of G\")\n",
    "# ax0.set_axis_off()\n",
    "\n",
    "ax1 = fig.add_subplot(axgrid[3:, :2])\n",
    "ax1.plot(degree_sequence, \"b-\", marker=\"o\")\n",
    "ax1.set_title(\"Degree Rank Plot\")\n",
    "ax1.set_ylabel(\"Degree\")\n",
    "ax1.set_xlabel(\"Rank\")\n",
    "\n",
    "ax2 = fig.add_subplot(axgrid[3:, 2:])\n",
    "ax2.bar(*np.unique(degree_sequence, return_counts=True))\n",
    "ax2.set_title(\"Degree histogram\")\n",
    "ax2.set_xlabel(\"Degree\")\n",
    "ax2.set_ylabel(\"# of Nodes\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8ea74d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Stats\n",
    "import math\n",
    "\n",
    "total_toots = len(toots_df)\n",
    "replies_count_df = toots_df.loc[toots_df['replies_count'] > 0]\n",
    "with_replies_pct = int(len(replies_count_df)/total_toots * 100)\n",
    "median = replies_count_df['replies_count'].median()\n",
    "\n",
    "print(\"\"\"\n",
    "Total Toots: {}\n",
    "With Replies: {}%\n",
    "Median Replies: {}\"\"\".format(total_toots, with_replies_pct, median))\n",
    "\n",
    "median_degree = degree_sequence[int(len(degree_sequence) / 2)]\n",
    "total_threads = (statuses_df['parent_account_id'] != statuses_df['parent_account_id'].shift(axis=0)).sum(axis=0)\n",
    "# closeness = nx.closeness_centrality(G) # This is slow\n",
    "# Average Closness {} hops - need to convert to hops - otherwise doesn't make sense\n",
    "cluster_coefficient = nx.average_clustering(G)\n",
    "\n",
    "\n",
    "print(\"\"\"\n",
    "Total Threads: {} \n",
    "Median Degree: {} conn/p\n",
    "Cluster Coefficient {}%\"\"\".format(total_threads, median_degree, round(cluster_coefficient * 100, 2)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
